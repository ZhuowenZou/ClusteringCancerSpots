{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%reload_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from util import *\n",
    "import numpy as np\n",
    "import sys\n",
    "import sklearn.cluster as clst\n",
    "import sklearn.mixture as mix\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import figure\n",
    "import pickle\n",
    "import random as rd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def birch_clustering(nodes, eps, n_clst = None):\n",
    "    # Fitting \n",
    "    batch_len = 1000\n",
    "    Birch_clst = clst.Birch(eps, n_clusters = None)\n",
    "    Birch_labels = []\n",
    "    for i in range(len(nodes)//batch_len):\n",
    "        Birch_clst.partial_fit(nodes[i*batch_len:(i+1)*batch_len])\n",
    "    Birch_clst.partial_fit(nodes[(len(nodes)//batch_len)*batch_len:])\n",
    "    \n",
    "    Birch_clst.set_params(n_clusters = n_clst)\n",
    "    print(\"Begin global fit\")\n",
    "    Birch_clst.partial_fit()\n",
    "    \n",
    "    print(\"Begin global labeling\")\n",
    "    Birch_labels = Birch_clst.predict(nodes)\n",
    "    print(\"max_label: \", max(Birch_labels))\n",
    "    \n",
    "    # Data collecting\n",
    "    Birch_stats, Birch_out = clst_stats(Birch_labels)\n",
    "\n",
    "    #out_liers\n",
    "    if n_clst is None:\n",
    "        Birch_out = Birch_stats[1]\n",
    "        Birch_stats[1] = 0\n",
    "    else:\n",
    "        Birch_stats[1] = 0\n",
    "        Birch_out = n_clst - sum(Birch_stats)\n",
    "    Birch_error = SSE(nodes, Birch_labels, Birch_clst.subcluster_centers_)\n",
    "\n",
    "    summa = sum([i*Birch_stats[i] for i in range(len(Birch_stats))])\n",
    "    print(\"Number of nodes getting clustered: \", summa)\n",
    "    print(\"Number of clusters: \", sum(Birch_stats))\n",
    "    print(\"Number of outliers: \", Birch_out)\n",
    "    print(\"MSE: \", Birch_error/summa)\n",
    "    \n",
    "    return Birch_labels, Birch_stats, Birch_out, Birch_error/summa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "Config = {}\n",
    "Config[\"directory\"] = \"./data/\"\n",
    "Config[\"folders\"] = [\"7-1\"]\n",
    "Config[\"filenames\"] = [\"real-data\", \"data-max\", \"data-middle\", \"data-min\", \"data-uniform\"]\n",
    "epsilons = [0.04, 0.05, 0.06, 0.07, 0.08]\n",
    "figsizes = [50, 200]\n",
    "np.set_printoptions(suppress=True)\n",
    "#np.set_printoptions(threshold=sys.maxsize)\n",
    "np.set_printoptions(threshold=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading data from and generating Birch results for real-data:\n",
      "[[3.35217072 3.09887177]\n",
      " [3.67855408 4.52536652]\n",
      " [5.04166992 5.26780457]]\n",
      "Number of nodes:  128838\n",
      "Epsilon =  0.03  ###################################\n",
      "Begin global fit\n",
      "Begin global labeling\n"
     ]
    }
   ],
   "source": [
    "for k in range(len(Config[\"folders\"])):\n",
    "    \n",
    "    folder = Config[\"folders\"][k]\n",
    "    n_clsts = []\n",
    "    statsss = []\n",
    "    results = []\n",
    "\n",
    "    for i in range(len(Config[\"filenames\"])):\n",
    "\n",
    "        filename = Config[\"filenames\"][i]\n",
    "\n",
    "        #retrieve data from file\n",
    "        print(\"Reading data from and generating Birch results for %s:\"%filename)\n",
    "        x,y = read_data(Config[\"directory\"] + folder + \"/\"+ filename + \".xlsx\")\n",
    "\n",
    "        # transform data\n",
    "        nodes = np.asarray([x,y]).T\n",
    "        print(nodes[0:3])\n",
    "        np.random.shuffle(nodes)\n",
    "\n",
    "        print(\"Number of nodes: \", len(nodes))\n",
    "\n",
    "        # Do birchs\n",
    "        result = []\n",
    "        statss = []\n",
    "        n_clst = 0\n",
    "\n",
    "        for j in range(len(epsilons)):\n",
    "\n",
    "            # Do birch \n",
    "            epsilon = epsilons[j]\n",
    "            print(\"Epsilon = \", epsilon, \" ###################################\")\n",
    "            if i == 0:\n",
    "                labels, stats, out, MSE = birch_clustering(nodes, epsilon)\n",
    "                n_clst = int(out + sum(stats))\n",
    "                n_clsts.append(n_clst)\n",
    "                print(\"Birch estimated cluster number: \", n_clst)\n",
    "            else: \n",
    "                n_clst = n_clsts[j]\n",
    "                labels, stats, out, MSE = birch_clustering(nodes, epsilon, n_clst)\n",
    "            result.append((labels, stats, out, MSE))\n",
    "            stats[1] = out\n",
    "            statss.append(stats)\n",
    "            stats[1] = 0\n",
    "\n",
    "            plotter(stats, epsilon, \"birch\", folder + \"_\" + filename, 0, 100, n_clst)\n",
    "            weighted_plotter(stats, epsilon, \"birch\", folder + \"_\" + filename, 0, 100, n_clst)\n",
    "            for figsize in figsizes:\n",
    "                plot_graph(nodes[:,0], nodes[:,1], epsilon, n_clst, labels, \"Birch\", folder+\"_\"+filename, figsize)\n",
    "\n",
    "        # checkpoint  \n",
    "        results.append(result)\n",
    "        statsss.append(statss)\n",
    "\n",
    "    BIRCH = (n_clsts, results, Config[\"filenames\"], epsilons)\n",
    "    file = open(\"./BIRCH-%s.tar\"%(folder),\"wb\")\n",
    "    pickle.dump(BIRCH, file)\n",
    "    file.close()\n",
    "           \n",
    "    plot_chart(folder, Config[\"filenames\"], epsilons, statsss)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Random code\n",
    "statss = []\n",
    "for i in range(2):\n",
    "    stats = []\n",
    "    for j in range(3):\n",
    "        stats.append([rd.randint(0, k) for k in range(rd.randint(0, 100))])\n",
    "    statss.append(stats)\n",
    "print(len(statss))\n",
    "print(len(statss[0]))\n",
    "\n",
    "plot_chart(\"test\", [\"a\",\"b\"], [0.1, 0.2, 0.3], np.asarray(statss))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "cnn.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
